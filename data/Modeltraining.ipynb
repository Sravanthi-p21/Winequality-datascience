{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde2cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4174123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw/data.csv',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229b9dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc8f08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1599, 12)\n",
      "Cleaned shape: (1124, 12)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a copy to work on\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Remove outliers column by column using IQR\n",
    "for col in df_clean.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {df_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb16e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean.drop(columns=['quality'],axis=1)\n",
    "y=df_clean['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3648555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1124 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1124 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f808ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       5\n",
       "       ..\n",
       "1594    5\n",
       "1595    6\n",
       "1596    6\n",
       "1597    5\n",
       "1598    6\n",
       "Name: quality, Length: 1124, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b04dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((899, 11), (225, 11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "299d92f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59865106,  1.3013592 , -1.36390779, ...,  0.65544819,\n",
       "        -0.2527394 , -1.02087587],\n",
       "       [-0.39136362,  1.63976256, -0.18948521, ..., -1.58739073,\n",
       "        -1.67782896, -1.23492824],\n",
       "       [-0.11498036,  0.59378855,  0.48161341, ..., -0.11794454,\n",
       "        -0.43087559,  0.37046458],\n",
       "       ...,\n",
       "       [-0.87503432, -0.75982486, -0.02171055, ..., -0.50464091,\n",
       "        -0.43087559, -0.37871874],\n",
       "       [ 0.50688198, -1.86732675,  1.32048669, ...,  0.50076964,\n",
       "        -0.87621608, -1.02087587],\n",
       "       [-0.04588454, -1.19052004,  1.09678715, ...,  0.19141255,\n",
       "        -0.1636713 ,  0.37046458]], shape=(225, 11))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "X_train\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408fb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fit LabelEncoder on full y set\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7f150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Logistic Regression\n",
      "- Accuracy: 0.6133\n",
      "- F1 Score: 0.5968\n",
      "- precision_Score: 0.5922\n",
      "- recall_score: 0.6133\n",
      "- Confusion Matrix:\n",
      " [[ 0  3  2  0]\n",
      " [ 0 81 21  0]\n",
      " [ 1 39 51  6]\n",
      " [ 0  0 15  6]]\n",
      "- Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.66      0.79      0.72       102\n",
      "           6       0.57      0.53      0.55        97\n",
      "           7       0.50      0.29      0.36        21\n",
      "\n",
      "    accuracy                           0.61       225\n",
      "   macro avg       0.43      0.40      0.41       225\n",
      "weighted avg       0.59      0.61      0.60       225\n",
      "\n",
      "========================================\n",
      "📌 Decision Tree\n",
      "- Accuracy: 0.6044\n",
      "- F1 Score: 0.6104\n",
      "- precision_Score: 0.6225\n",
      "- recall_score: 0.6044\n",
      "- Confusion Matrix:\n",
      " [[ 2  2  1  0]\n",
      " [ 7 65 25  5]\n",
      " [ 0 28 56 13]\n",
      " [ 0  0  8 13]]\n",
      "- Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.22      0.40      0.29         5\n",
      "           5       0.68      0.64      0.66       102\n",
      "           6       0.62      0.58      0.60        97\n",
      "           7       0.42      0.62      0.50        21\n",
      "\n",
      "    accuracy                           0.60       225\n",
      "   macro avg       0.49      0.56      0.51       225\n",
      "weighted avg       0.62      0.60      0.61       225\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Random Forest\n",
      "- Accuracy: 0.6933\n",
      "- F1 Score: 0.6837\n",
      "- precision_Score: 0.6752\n",
      "- recall_score: 0.6933\n",
      "- Confusion Matrix:\n",
      " [[ 0  3  2  0]\n",
      " [ 0 82 20  0]\n",
      " [ 0 25 63  9]\n",
      " [ 0  0 10 11]]\n",
      "- Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.75      0.80      0.77       102\n",
      "           6       0.66      0.65      0.66        97\n",
      "           7       0.55      0.52      0.54        21\n",
      "\n",
      "    accuracy                           0.69       225\n",
      "   macro avg       0.49      0.49      0.49       225\n",
      "weighted avg       0.68      0.69      0.68       225\n",
      "\n",
      "========================================\n",
      "📌 Gradient Boosting\n",
      "- Accuracy: 0.6889\n",
      "- F1 Score: 0.6812\n",
      "- precision_Score: 0.6787\n",
      "- recall_score: 0.6889\n",
      "- Confusion Matrix:\n",
      " [[ 0  3  2  0]\n",
      " [ 1 83 18  0]\n",
      " [ 1 28 58 10]\n",
      " [ 0  0  7 14]]\n",
      "- Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.73      0.81      0.77       102\n",
      "           6       0.68      0.60      0.64        97\n",
      "           7       0.58      0.67      0.62        21\n",
      "\n",
      "    accuracy                           0.69       225\n",
      "   macro avg       0.50      0.52      0.51       225\n",
      "weighted avg       0.68      0.69      0.68       225\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 AdaBoost\n",
      "- Accuracy: 0.6311\n",
      "- F1 Score: 0.5907\n",
      "- precision_Score: 0.5572\n",
      "- recall_score: 0.6311\n",
      "- Confusion Matrix:\n",
      " [[ 0  3  2  0]\n",
      " [ 0 84 18  0]\n",
      " [ 0 38 58  1]\n",
      " [ 0  0 21  0]]\n",
      "- Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.67      0.82      0.74       102\n",
      "           6       0.59      0.60      0.59        97\n",
      "           7       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.63       225\n",
      "   macro avg       0.31      0.36      0.33       225\n",
      "weighted avg       0.56      0.63      0.59       225\n",
      "\n",
      "========================================\n",
      "📌 SVC\n",
      "- Accuracy: 0.6400\n",
      "- F1 Score: 0.6220\n",
      "- precision_Score: 0.6160\n",
      "- recall_score: 0.6400\n",
      "- Confusion Matrix:\n",
      " [[ 0  3  2  0]\n",
      " [ 0 83 19  0]\n",
      " [ 0 36 55  6]\n",
      " [ 0  1 14  6]]\n",
      "- Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.67      0.81      0.74       102\n",
      "           6       0.61      0.57      0.59        97\n",
      "           7       0.50      0.29      0.36        21\n",
      "\n",
      "    accuracy                           0.64       225\n",
      "   macro avg       0.45      0.42      0.42       225\n",
      "weighted avg       0.62      0.64      0.62       225\n",
      "\n",
      "========================================\n",
      "📌 K-Nearest Neighbors\n",
      "- Accuracy: 0.5911\n",
      "- F1 Score: 0.5868\n",
      "- precision_Score: 0.5827\n",
      "- recall_score: 0.5911\n",
      "- Confusion Matrix:\n",
      " [[ 0  3  2  0]\n",
      " [ 0 67 34  1]\n",
      " [ 1 28 56 12]\n",
      " [ 0  3  8 10]]\n",
      "- Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.66      0.66      0.66       102\n",
      "           6       0.56      0.58      0.57        97\n",
      "           7       0.43      0.48      0.45        21\n",
      "\n",
      "    accuracy                           0.59       225\n",
      "   macro avg       0.41      0.43      0.42       225\n",
      "weighted avg       0.58      0.59      0.59       225\n",
      "\n",
      "========================================\n",
      "📌 CatBoost\n",
      "- Accuracy: 0.7156\n",
      "- F1 Score: 0.7066\n",
      "- precision_Score: 0.6997\n",
      "- recall_score: 0.7156\n",
      "- Confusion Matrix:\n",
      " [[ 0  3  2  0]\n",
      " [ 0 83 18  1]\n",
      " [ 0 24 64  9]\n",
      " [ 0  0  7 14]]\n",
      "- Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.75      0.81      0.78       102\n",
      "           6       0.70      0.66      0.68        97\n",
      "           7       0.58      0.67      0.62        21\n",
      "\n",
      "    accuracy                           0.72       225\n",
      "   macro avg       0.51      0.54      0.52       225\n",
      "weighted avg       0.70      0.72      0.71       225\n",
      "\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\anish\\OneDrive\\Desktop\\sravanthi\\Sravanthi vinjamuri\\Winequality-datascience\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define classification models\n",
    "class_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \n",
    "    \"CatBoost\": CatBoostClassifier(verbose=False)\n",
    "}\n",
    "\n",
    "# Lists to store results\n",
    "class_model_names = []\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def evaluate_classification_basic(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, f1, precision, recall, cm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for name, model in class_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc,f1,precision,recall,cm= evaluate_classification_basic(y_test, y_pred)\n",
    "    \n",
    "    class_model_names.append(name)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    accuracy_scores.append(acc)\n",
    "    f1_scores.append(f1)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    \n",
    "    print(f\"📌 {name}\")\n",
    "    print(\"- Accuracy: {:.4f}\".format(acc))\n",
    "    print(\"- F1 Score: {:.4f}\".format(f1))\n",
    "    print(\"- precision_Score: {:.4f}\".format(precision))\n",
    "    print(\"- recall_score: {:.4f}\".format(recall))\n",
    "    print(\"- Confusion Matrix:\\n\", cm)\n",
    "    print(\"- Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"=\"*40)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fa07d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.5820\n",
      "- Mean Absolute Error: 0.4650\n",
      "- R2 Score: 0.3677\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.5325\n",
      "- Mean Absolute Error: 0.4344\n",
      "- R2 Score: 0.3992\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.7320\n",
      "- Mean Absolute Error: 0.6413\n",
      "- R2 Score: 0.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.6879\n",
      "- Mean Absolute Error: 0.6092\n",
      "- R2 Score: -0.0025\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.5820\n",
      "- Mean Absolute Error: 0.4650\n",
      "- R2 Score: 0.3677\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.5325\n",
      "- Mean Absolute Error: 0.4344\n",
      "- R2 Score: 0.3993\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.4876\n",
      "- Mean Absolute Error: 0.3691\n",
      "- R2 Score: 0.5563\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.5958\n",
      "- Mean Absolute Error: 0.4720\n",
      "- R2 Score: 0.2478\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0000\n",
      "- Mean Absolute Error: 0.0000\n",
      "- R2 Score: 1.0000\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.7542\n",
      "- Mean Absolute Error: 0.4622\n",
      "- R2 Score: -0.2053\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.2027\n",
      "- Mean Absolute Error: 0.1468\n",
      "- R2 Score: 0.9233\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.5046\n",
      "- Mean Absolute Error: 0.3862\n",
      "- R2 Score: 0.4605\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.0145\n",
      "- Mean Absolute Error: 0.0095\n",
      "- R2 Score: 0.9996\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.5483\n",
      "- Mean Absolute Error: 0.3821\n",
      "- R2 Score: 0.3629\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.1751\n",
      "- Mean Absolute Error: 0.1306\n",
      "- R2 Score: 0.9428\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.5229\n",
      "- Mean Absolute Error: 0.3976\n",
      "- R2 Score: 0.4206\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.5547\n",
      "- Mean Absolute Error: 0.4451\n",
      "- R2 Score: 0.4257\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 0.5729\n",
      "- Mean Absolute Error: 0.4601\n",
      "- R2 Score: 0.3047\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define regression models\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    def evaluate_model(true, predicted):\n",
    "        mae = mean_absolute_error(true, predicted)\n",
    "        mse = mean_squared_error(true, predicted)\n",
    "        rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "        r2_square = r2_score(true, predicted)\n",
    "        return mae, rmse, r2_square\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
